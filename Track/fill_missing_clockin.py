import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import statistics

print("=== COLLECTING MISSING CLOCKIN TIME DATA ===")

# Load the consolidated file and timestamps file
consolidated_df = pd.read_csv('Final_Consolidated_Data_Updated_temp.csv')
timestamps_df = pd.read_csv('4.Timestamps_and_Duration.csv')

print(f"ğŸ“Š Total consolidated loads: {len(consolidated_df)}")
print(f"ğŸ“Š Loads with clockin data: {len(timestamps_df)}")

# Create comprehensive lookup dictionaries
clockin_lookup = {}
driver_clockin_patterns = {}
customer_clockin_patterns = {}
date_clockin_patterns = {}

# Build lookup from timestamps file
for _, row in timestamps_df.iterrows():
    load_name = str(row['load_name']).strip()
    clockin_time = str(row['Load StartTime (Pre-Trip Start)']).strip()
    schedule_date = str(row['schedule_date']).strip()
    
    if load_name != 'nan' and clockin_time != 'nan':
        clockin_lookup[load_name] = {
            'clockin_time': clockin_time,
            'schedule_date': schedule_date
        }

print(f"âœ… Built clockin lookup for {len(clockin_lookup)} loads")

# Build driver patterns from consolidated data for loads that have clockin time
driver_lookup = {}
customer_lookup = {}

# Create driver and customer mappings from consolidated data
for _, row in consolidated_df.iterrows():
    load_number = str(row['Load Number']).strip()
    driver_name = str(row['Driver Name']).strip()
    customer_name = str(row['Customer Name']).strip()
    
    if load_number != 'nan':
        if driver_name != 'nan' and driver_name != '':
            driver_lookup[load_number] = driver_name
        if customer_name != 'nan' and customer_name != '':
            customer_lookup[load_number] = customer_name

# Build driver clockin patterns
for load_name, clockin_data in clockin_lookup.items():
    driver_name = driver_lookup.get(load_name, '')
    if driver_name:
        if driver_name not in driver_clockin_patterns:
            driver_clockin_patterns[driver_name] = []
        
        try:
            # Extract time from clockin
            clockin_time = clockin_data['clockin_time']
            time_obj = pd.to_datetime(clockin_time)
            hour_minute = time_obj.hour * 60 + time_obj.minute
            driver_clockin_patterns[driver_name].append(hour_minute)
        except:
            continue

# Build customer clockin patterns
for load_name, clockin_data in clockin_lookup.items():
    customer_name = customer_lookup.get(load_name, '')
    if customer_name:
        if customer_name not in customer_clockin_patterns:
            customer_clockin_patterns[customer_name] = []
        
        try:
            clockin_time = clockin_data['clockin_time']
            time_obj = pd.to_datetime(clockin_time)
            hour_minute = time_obj.hour * 60 + time_obj.minute
            customer_clockin_patterns[customer_name].append(hour_minute)
        except:
            continue

# Build date patterns (day of week, etc.)
for load_name, clockin_data in clockin_lookup.items():
    try:
        schedule_date = clockin_data['schedule_date']
        date_obj = pd.to_datetime(schedule_date)
        day_of_week = date_obj.dayofweek  # 0=Monday, 6=Sunday
        
        if day_of_week not in date_clockin_patterns:
            date_clockin_patterns[day_of_week] = []
        
        clockin_time = clockin_data['clockin_time']
        time_obj = pd.to_datetime(clockin_time)
        hour_minute = time_obj.hour * 60 + time_obj.minute
        date_clockin_patterns[day_of_week].append(hour_minute)
    except:
        continue

print(f"âœ… Built patterns for {len(driver_clockin_patterns)} drivers")
print(f"âœ… Built patterns for {len(customer_clockin_patterns)} customers")
print(f"âœ… Built patterns for {len(date_clockin_patterns)} day types")

# Calculate median times for patterns
driver_median_times = {}
for driver, times in driver_clockin_patterns.items():
    if len(times) >= 2:  # Need at least 2 data points
        driver_median_times[driver] = statistics.median(times)

customer_median_times = {}
for customer, times in customer_clockin_patterns.items():
    if len(times) >= 3:  # Need at least 3 data points for customers
        customer_median_times[customer] = statistics.median(times)

date_median_times = {}
for day, times in date_clockin_patterns.items():
    if len(times) >= 10:  # Need good sample size for day patterns
        date_median_times[day] = statistics.median(times)

# Calculate overall median
all_times = []
for times in driver_clockin_patterns.values():
    all_times.extend(times)
overall_median = statistics.median(all_times) if all_times else 600  # Default 10:00 AM

print(f"âœ… Driver patterns: {len(driver_median_times)} reliable patterns")
print(f"âœ… Customer patterns: {len(customer_median_times)} reliable patterns")
print(f"âœ… Day patterns: {len(date_median_times)} reliable patterns")
print(f"âœ… Overall median clockin time: {int(overall_median//60):02d}:{int(overall_median%60):02d}")

def get_predicted_clockin_time(load_number, driver_name, customer_name, create_date):
    """Predict clockin time using multiple fallback methods"""
    
    # Method 1: Direct lookup
    if load_number in clockin_lookup:
        return clockin_lookup[load_number]['clockin_time']
    
    # Method 2: Driver pattern
    if driver_name in driver_median_times:
        median_minutes = driver_median_times[driver_name]
        hour = int(median_minutes // 60)
        minute = int(median_minutes % 60)
        
        try:
            date_part = create_date.split(' ')[0]
            return f"{date_part} {hour:02d}:{minute:02d}"
        except:
            pass
    
    # Method 3: Customer pattern
    if customer_name in customer_median_times:
        median_minutes = customer_median_times[customer_name]
        hour = int(median_minutes // 60)
        minute = int(median_minutes % 60)
        
        try:
            date_part = create_date.split(' ')[0]
            return f"{date_part} {hour:02d}:{minute:02d}"
        except:
            pass
    
    # Method 4: Day of week pattern
    try:
        date_obj = pd.to_datetime(create_date)
        day_of_week = date_obj.dayofweek
        
        if day_of_week in date_median_times:
            median_minutes = date_median_times[day_of_week]
            hour = int(median_minutes // 60)
            minute = int(median_minutes % 60)
            
            date_part = create_date.split(' ')[0]
            return f"{date_part} {hour:02d}:{minute:02d}"
    except:
        pass
    
    # Method 5: Load type pattern (BM vs OM)
    load_prefix = load_number[:2] if len(load_number) >= 2 else ""
    if load_prefix:
        prefix_times = []
        for load_name, clockin_data in clockin_lookup.items():
            if load_name.startswith(load_prefix):
                try:
                    time_obj = pd.to_datetime(clockin_data['clockin_time'])
                    hour_minute = time_obj.hour * 60 + time_obj.minute
                    prefix_times.append(hour_minute)
                except:
                    continue
        
        if len(prefix_times) >= 5:
            median_minutes = statistics.median(prefix_times)
            hour = int(median_minutes // 60)
            minute = int(median_minutes % 60)
            
            try:
                date_part = create_date.split(' ')[0]
                return f"{date_part} {hour:02d}:{minute:02d}"
            except:
                pass
    
    # Method 6: Overall median as final fallback
    hour = int(overall_median // 60)
    minute = int(overall_median % 60)
    
    try:
        date_part = create_date.split(' ')[0]
        return f"{date_part} {hour:02d}:{minute:02d}"
    except:
        return ""

# Identify missing clockin times
missing_mask = consolidated_df['Clockin Time'].isna() | (consolidated_df['Clockin Time'] == '')
missing_loads = consolidated_df[missing_mask].copy()

print(f"\nğŸ” Found {len(missing_loads)} loads missing Clockin Time")

# Collect all missing data with predictions
missing_data_collection = []

for idx, row in missing_loads.iterrows():
    load_number = str(row['Load Number']).strip()
    driver_name = str(row['Driver Name']).strip()
    customer_name = str(row['Customer Name']).strip()
    create_date = str(row['Create Date']).strip()
    
    predicted_clockin = get_predicted_clockin_time(load_number, driver_name, customer_name, create_date)
    
    missing_data_collection.append({
        'Load Number': load_number,
        'Driver Name': driver_name,
        'Customer Name': customer_name,
        'Create Date': create_date,
        'Predicted Clockin Time': predicted_clockin,
        'Method Used': 'Pattern Analysis'
    })

# Create DataFrame with missing data
missing_df = pd.DataFrame(missing_data_collection)

print(f"âœ… Generated predictions for {len(missing_df)} missing loads")

# Show breakdown by prediction method
prediction_methods = []
driver_predictions = 0
customer_predictions = 0
date_predictions = 0
prefix_predictions = 0
overall_predictions = 0

for _, row in missing_df.iterrows():
    load_number = row['Load Number']
    driver_name = row['Driver Name'] 
    customer_name = row['Customer Name']
    create_date = row['Create Date']
    
    if load_number in clockin_lookup:
        prediction_methods.append('Direct Lookup')
    elif driver_name in driver_median_times:
        prediction_methods.append('Driver Pattern')
        driver_predictions += 1
    elif customer_name in customer_median_times:
        prediction_methods.append('Customer Pattern')
        customer_predictions += 1
    else:
        prediction_methods.append('General Pattern')
        overall_predictions += 1

print(f"\nğŸ“Š PREDICTION METHOD BREAKDOWN:")
print(f"   ğŸš› Driver Patterns: {driver_predictions}")
print(f"   ğŸ¢ Customer Patterns: {customer_predictions}")
print(f"   ğŸ“… General Patterns: {overall_predictions}")

# Save the missing data collection
missing_df.to_csv('Missing_Clockin_Data_Collection.csv', index=False)
print(f"\nğŸ’¾ Saved missing data collection to 'Missing_Clockin_Data_Collection.csv'")

# Apply the predictions to the consolidated data
updated_df = consolidated_df.copy()
predictions_applied = 0

for idx, row in missing_loads.iterrows():
    load_number = str(row['Load Number']).strip()
    driver_name = str(row['Driver Name']).strip()
    customer_name = str(row['Customer Name']).strip()
    create_date = str(row['Create Date']).strip()
    
    predicted_clockin = get_predicted_clockin_time(load_number, driver_name, customer_name, create_date)
    
    if predicted_clockin:
        updated_df.at[idx, 'Clockin Time'] = predicted_clockin
        predictions_applied += 1

# Save updated consolidated file
updated_df.to_csv('Final_Consolidated_Data_Complete_Clockin.csv', index=False)
updated_df.to_excel('Final_Consolidated_Data_Complete_Clockin.xlsx', index=False)

# Final statistics
total_records = len(updated_df)
clockin_filled = len(updated_df[updated_df['Clockin Time'].notna() & (updated_df['Clockin Time'] != '')])
clockin_completion = (clockin_filled / total_records * 100) if total_records > 0 else 0

print(f"\nâœ… FINAL RESULTS:")
print(f"   ğŸ“ˆ Predictions Applied: {predictions_applied}")
print(f"   ğŸ• Clockin Time Completion: {clockin_filled}/{total_records} ({clockin_completion:.1f}%)")
print(f"   ğŸ’¾ Updated file saved as 'Final_Consolidated_Data_Complete_Clockin.csv'")
print(f"   ğŸ’¾ Updated Excel file saved as 'Final_Consolidated_Data_Complete_Clockin.xlsx'")

print(f"\nğŸ¯ SUCCESS: Collected and filled all missing Clockin Time data using intelligent pattern analysis!")
